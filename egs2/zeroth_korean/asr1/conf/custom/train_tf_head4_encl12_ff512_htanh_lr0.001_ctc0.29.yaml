accum_grad: 1
batch_size: 128
batch_type: folded
best_model_criterion:
- - valid
  - acc
  - max
decoder: transformer
decoder_conf:
  attention_heads: 4
  dropout_rate: 0.1
  linear_units: 512
  num_blocks: 6
  positional_dropout_rate: 0.1
  prune_act: htanh
  self_attention_dropout_rate: 0.0
  src_attention_dropout_rate: 0.0
encoder: transformer
encoder_conf:
  attention_dropout_rate: 0.0
  attention_heads: 4
  dropout_rate: 0.1
  input_layer: conv2d
  linear_units: 512
  normalize_before: true
  num_blocks: 12
  output_size: 256
  positional_dropout_rate: 0.1
  prune_act: htanh
init: xavier_uniform
keep_nbest_models: 10
max_epoch: 200
model_conf:
  ctc_weight: 0.29
  length_normalized_loss: false
  lsm_weight: 0.1
optim: adam
optim_conf:
  lr: 0.001
patience: none
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 25000
