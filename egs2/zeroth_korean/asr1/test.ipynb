{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('speech': conda)",
   "metadata": {
    "interpreter": {
     "hash": "611231d50d89399c7812e642eac108257e44491cbc2ead4a7a526b1be52f90d6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeroth_data_loader import zeroth_dataset\n",
    "from zeroth_model_loader import load_model\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = zeroth_dataset()\n",
    "speech2text, att_hook = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = speech2text.asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('108_003_0510',\n",
       " {'speech': array([ 0.0000000e+00,  3.0517578e-05,  3.0517578e-05, ...,\n",
       "         -1.2207031e-04,  1.8310547e-04, -1.2207031e-04], dtype=float32),\n",
       "  'text': array([  39,   31,   16,  431,  395,   96, 1670,   53,  129,  538,  272,\n",
       "          883,   17,  239,  345,  149,    8,  634])})"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset[audio_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = dataset[audio_num][1]['speech']\n",
    "text = dataset[audio_num][1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  39   31   16  431  395   96 1670   53  129  538  272  883   17  239\n  345  149    8  634]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = speech2text(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('십 오 일 박근혜 대통령 변호인 으로 유영하 변호사가 선임 됐다고 알려졌다', ['▁십', '▁오', '▁일', '▁박근', '혜', '▁대통령', '▁변호인', '▁으로', '▁유', '영', '하', '▁변호사', '가', '▁선', '임', '▁됐다', '고', '▁알려졌다'], [39, 31, 16, 431, 395, 96, 1670, 53, 129, 538, 272, 883, 17, 239, 345, 149, 8, 634], Hypothesis(yseq=tensor([4999,   39,   31,   16,  431,  395,   96, 1670,   53,  129,  538,  272,\n         883,   17,  239,  345,  149,    8,  634, 4999]), score=tensor(-0.7858), scores={'decoder': tensor(-1.0655), 'ctc': tensor(-0.1331)}, states={'decoder': [tensor([[ 13.2585,  12.8527,  20.5330,  ..., -12.5912,  -5.2187,  -8.7967],\n        [-35.0648, -43.9827,  29.0886,  ..., 107.0360,  13.1104,  -9.4621],\n        [ -2.1222, -12.9658,   9.8999,  ...,  -2.7065, -74.0307,  -8.4262],\n        ...,\n        [-30.5417,   8.6932, -71.7479,  ..., -18.7957,  17.9572,  18.0615],\n        [-41.9889,  37.7411,  10.6708,  ..., -17.3122,  -5.2566, -24.5943],\n        [ 28.0681,  59.9926,  -1.2841,  ..., -12.9057, -20.4175,  33.3011]],\n       grad_fn=<SelectBackward>), tensor([[ 26.7771,  18.0755,  27.2023,  ..., -20.6422,  -1.0837, -16.0136],\n        [-28.0657, -45.5899,  37.0428,  ..., 110.0669,  25.9839, -15.2382],\n        [  0.9743, -14.8922,  12.0065,  ..., -13.6277, -84.3061,  -8.9623],\n        ...,\n        [-43.4466,   1.4751, -63.8750,  ..., -20.0595,  17.4924,  20.3758],\n        [-47.4575,  36.3433,  33.9379,  ..., -19.1509,   4.7871, -16.7370],\n        [ 19.0913,  56.3952,  -9.4187,  ..., -33.6394,   0.4514,  27.2466]],\n       grad_fn=<SelectBackward>), tensor([[ 24.0522,  18.1599,  20.9737,  ..., -23.0691, -12.2623, -13.3232],\n        [-37.9187, -48.2638,  29.4137,  ..., 117.3125,  24.1500, -11.4187],\n        [-18.1304, -35.1906,   7.8184,  ..., -10.3104, -92.7303,   0.6470],\n        ...,\n        [-45.5391, -12.6534, -64.0066,  ..., -36.6092,  24.1999,  25.9589],\n        [-66.7794,  28.9071,  34.5356,  ..., -24.4399, -35.7224, -33.5640],\n        [ 24.9505,  91.8281, -13.3885,  ..., -60.7102,  -2.4211,  49.9864]],\n       grad_fn=<SelectBackward>), tensor([[-1.2028e+01,  5.6741e+00,  2.0478e+01,  ..., -6.6248e+01,\n         -5.2691e+00, -3.8644e+01],\n        [-2.7731e+01, -4.7258e+01,  1.3948e+01,  ...,  1.0435e+02,\n          1.6260e+01, -6.6743e+00],\n        [-1.6607e+01, -3.4751e+01, -1.4717e+00,  ..., -3.1419e+01,\n         -1.1416e+02,  1.2578e+01],\n        ...,\n        [-4.4772e+01, -1.4483e+01, -6.8801e+01,  ..., -4.0897e+01,\n          3.2673e+01,  1.9350e+01],\n        [-7.9831e+01,  4.4533e+01,  2.6144e+01,  ...,  3.3055e-02,\n         -5.9774e+01, -1.3330e+00],\n        [ 5.1633e+01,  9.4137e+01, -1.5703e+01,  ..., -9.7066e+01,\n          3.9275e+00,  6.0684e+01]], grad_fn=<SelectBackward>), tensor([[  -7.1177,   50.4000,   20.0709,  ..., -143.8031,   10.4765,\n            7.3722],\n        [ -23.6025, -105.4896,  -33.5438,  ...,   94.8877,    3.1967,\n           12.6783],\n        [ -32.4481,  -39.8210,   -7.0741,  ...,  -26.6284, -101.0246,\n           80.1764],\n        ...,\n        [   5.1931,  -47.1913,  -63.4197,  ...,  -64.5454,   -0.2079,\n            4.1837],\n        [-119.6465,   38.6139,   58.4966,  ...,   13.4124, -134.6357,\n           -1.2512],\n        [ 193.2195,  171.5723,  -65.0726,  ..., -109.5636,    1.7102,\n           85.6421]], grad_fn=<SelectBackward>), tensor([[-200.2623,  340.5178, -218.8089,  ..., -308.9313, -624.4454,\n          -65.7834],\n        [-141.3639,  219.8785, -270.5177,  ...,  856.3539, -490.3636,\n          113.4758],\n        [-752.8925,  210.7441, -221.4079,  ...,  594.6766, -759.3934,\n          194.7238],\n        ...,\n        [-178.5767, -212.7252,  195.9948,  ..., -195.6918,  -75.0149,\n         -692.7543],\n        [-264.3369,   14.9287,  -40.4289,  ...,  140.7673,  -36.6690,\n         -111.7098],\n        [ 435.2376, -119.4603, -722.7418,  ...,  927.1699, -939.7017,\n          444.9764]], grad_fn=<SelectBackward>)], 'ctc': (tensor([[-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-1.0000e+10, -1.0000e+10],\n        [-5.7008e+02, -1.0000e+10],\n        [-5.7053e+02, -5.7008e+02],\n        [-5.6674e+02, -5.6959e+02],\n        [-5.6310e+02, -5.8222e+02],\n        [-5.5616e+02, -5.6675e+02],\n        [-5.5745e+02, -5.5616e+02],\n        [-5.5355e+02, -5.5592e+02],\n        [-5.4931e+02, -5.5346e+02],\n        [-5.5532e+02, -5.6284e+02],\n        [-5.5836e+02, -5.7371e+02],\n        [-5.6000e+02, -5.6644e+02],\n        [-5.6086e+02, -5.6000e+02],\n        [-5.5691e+02, -5.5976e+02],\n        [-5.5901e+02, -5.6332e+02],\n        [-5.6102e+02, -5.6258e+02],\n        [-5.6531e+02, -5.6083e+02],\n        [-5.6485e+02, -5.6081e+02],\n        [-5.6648e+02, -5.6080e+02],\n        [-5.7088e+02, -5.6709e+02],\n        [-5.8195e+02, -5.8147e+02],\n        [-5.9382e+02, -5.8814e+02],\n        [-5.9784e+02, -5.8814e+02],\n        [-5.9559e+02, -5.8814e+02],\n        [-5.9123e+02, -5.8814e+02],\n        [-5.8592e+02, -5.9935e+02],\n        [-5.6779e+02, -6.0400e+02],\n        [-5.5025e+02, -5.6780e+02],\n        [-5.3292e+02, -5.5025e+02],\n        [-5.2787e+02, -5.3292e+02],\n        [-5.2505e+02, -5.2787e+02],\n        [-5.2047e+02, -5.2499e+02],\n        [-5.1802e+02, -5.2046e+02],\n        [-5.1133e+02, -5.1794e+02],\n        [-5.0981e+02, -5.1133e+02],\n        [-5.1051e+02, -5.0962e+02],\n        [-5.0597e+02, -5.0927e+02],\n        [-5.0032e+02, -5.0593e+02],\n        [-4.8602e+02, -5.0487e+02],\n        [-4.6585e+02, -5.0095e+02],\n        [-4.5790e+02, -4.6637e+02],\n        [-4.5625e+02, -4.5790e+02],\n        [-4.5301e+02, -4.5607e+02],\n        [-4.5259e+02, -4.5296e+02],\n        [-4.4882e+02, -4.5207e+02],\n        [-4.4549e+02, -4.4878e+02],\n        [-4.4847e+02, -4.4545e+02],\n        [-4.5039e+02, -4.4540e+02],\n        [-4.4557e+02, -4.4540e+02],\n        [-4.3894e+02, -4.4479e+02],\n        [-4.2671e+02, -4.3893e+02],\n        [-4.1043e+02, -4.2671e+02],\n        [-3.9379e+02, -4.1043e+02],\n        [-3.8838e+02, -3.9379e+02],\n        [-3.8458e+02, -3.8873e+02],\n        [-3.8331e+02, -3.9817e+02],\n        [-3.7571e+02, -3.8934e+02],\n        [-3.7521e+02, -3.7571e+02],\n        [-3.7486e+02, -3.7474e+02],\n        [-3.7480e+02, -3.7410e+02],\n        [-3.6836e+02, -3.7370e+02],\n        [-3.5929e+02, -3.6835e+02],\n        [-3.5405e+02, -3.5929e+02],\n        [-3.4952e+02, -3.5404e+02],\n        [-3.4751e+02, -3.4951e+02],\n        [-3.4411e+02, -3.4738e+02],\n        [-3.4190e+02, -3.4407e+02],\n        [-3.2537e+02, -3.4179e+02],\n        [-3.0198e+02, -3.2538e+02],\n        [-2.8766e+02, -3.0198e+02],\n        [-2.9087e+02, -2.8766e+02],\n        [-2.8899e+02, -2.8762e+02],\n        [-2.8375e+02, -2.9700e+02],\n        [-2.8791e+02, -2.8375e+02],\n        [-2.8717e+02, -2.8374e+02],\n        [-2.8538e+02, -2.8370e+02],\n        [-2.8282e+02, -2.8353e+02],\n        [-2.7965e+02, -2.8242e+02],\n        [-2.7846e+02, -2.7959e+02],\n        [-2.7826e+02, -2.7818e+02],\n        [-2.7735e+02, -2.7752e+02],\n        [-2.7243e+02, -2.7674e+02],\n        [-2.6828e+02, -2.7242e+02],\n        [-2.6766e+02, -2.6826e+02],\n        [-2.6722e+02, -2.6722e+02],\n        [-2.6809e+02, -2.6653e+02],\n        [-2.6508e+02, -2.6636e+02],\n        [-2.6902e+02, -2.7617e+02],\n        [-2.7509e+02, -2.8447e+02],\n        [-2.8263e+02, -2.8043e+02],\n        [-2.8630e+02, -2.8033e+02],\n        [-2.8680e+02, -2.8033e+02],\n        [-2.8652e+02, -2.8032e+02],\n        [-2.8511e+02, -2.8032e+02],\n        [-2.8533e+02, -2.8031e+02],\n        [-2.8276e+02, -2.8031e+02],\n        [-2.7890e+02, -2.8068e+02],\n        [-2.7366e+02, -2.8224e+02],\n        [-2.5508e+02, -2.7369e+02],\n        [-2.5206e+02, -2.5508e+02],\n        [-2.5004e+02, -2.5202e+02],\n        [-2.4696e+02, -2.4991e+02],\n        [-2.3849e+02, -2.4691e+02],\n        [-2.3223e+02, -2.3849e+02],\n        [-2.2454e+02, -2.3767e+02],\n        [-2.1962e+02, -2.2454e+02],\n        [-2.2615e+02, -2.1961e+02],\n        [-2.2208e+02, -2.1961e+02],\n        [-2.2169e+02, -2.1953e+02],\n        [-2.2130e+02, -2.1942e+02],\n        [-2.2073e+02, -2.1927e+02],\n        [-2.2039e+02, -2.1907e+02],\n        [-2.1387e+02, -2.1883e+02],\n        [-1.9949e+02, -2.1387e+02],\n        [-1.9486e+02, -1.9949e+02],\n        [-1.9094e+02, -1.9485e+02],\n        [-1.8988e+02, -1.9092e+02],\n        [-1.8938e+02, -1.8958e+02],\n        [-1.8887e+02, -1.8878e+02],\n        [-1.8856e+02, -1.8813e+02],\n        [-1.8831e+02, -1.8763e+02],\n        [-1.8831e+02, -1.8722e+02],\n        [-1.8694e+02, -1.8693e+02],\n        [-1.8067e+02, -1.8624e+02],\n        [-1.8304e+02, -1.8067e+02],\n        [-1.8484e+02, -1.8058e+02],\n        [-1.8369e+02, -1.8056e+02],\n        [-1.8141e+02, -1.8052e+02],\n        [-1.8443e+02, -1.8018e+02],\n        [-1.8114e+02, -1.8016e+02],\n        [-1.8195e+02, -1.7984e+02],\n        [-1.8561e+02, -1.8688e+02],\n        [-1.9218e+02, -1.9997e+02],\n        [-1.9536e+02, -1.9218e+02],\n        [-1.9522e+02, -1.9214e+02],\n        [-1.9025e+02, -1.9211e+02],\n        [-1.9649e+02, -2.0587e+02],\n        [-2.0086e+02, -1.9649e+02],\n        [-1.9642e+02, -1.9647e+02],\n        [-1.9385e+02, -1.9575e+02],\n        [-1.9445e+02, -1.9371e+02],\n        [-1.8688e+02, -2.1219e+02],\n        [-1.7803e+02, -1.8981e+02],\n        [-1.7892e+02, -1.7803e+02],\n        [-1.7468e+02, -1.7769e+02],\n        [-1.6785e+02, -1.8101e+02],\n        [-1.5538e+02, -1.7212e+02],\n        [-1.4723e+02, -1.5541e+02],\n        [-1.3524e+02, -1.4723e+02],\n        [-1.1661e+02, -1.3524e+02],\n        [-1.0960e+02, -1.1661e+02],\n        [-1.1353e+02, -1.0960e+02],\n        [-1.1011e+02, -1.0958e+02],\n        [-1.0840e+02, -1.0912e+02],\n        [-1.0409e+02, -1.0800e+02],\n        [-9.5013e+01, -1.1242e+02],\n        [-8.7737e+01, -9.5013e+01],\n        [-8.8956e+01, -8.7736e+01],\n        [-8.4371e+01, -8.7477e+01],\n        [-8.5649e+01, -8.4327e+01],\n        [-8.5515e+01, -8.9174e+01],\n        [-8.5247e+01, -1.0056e+02],\n        [-7.1958e+01, -8.5247e+01],\n        [-5.9739e+01, -7.1958e+01],\n        [-5.2652e+01, -5.9739e+01],\n        [-5.7065e+01, -5.2651e+01],\n        [-5.8545e+01, -5.2639e+01],\n        [-5.8718e+01, -5.2636e+01],\n        [-5.8247e+01, -5.2634e+01],\n        [-5.8702e+01, -5.2630e+01],\n        [-6.0224e+01, -5.2628e+01],\n        [-5.6747e+01, -5.2627e+01],\n        [-5.9720e+01, -5.2611e+01],\n        [-5.6155e+01, -5.2610e+01],\n        [-5.9100e+01, -5.2582e+01],\n        [-6.0751e+01, -5.2580e+01],\n        [-5.7793e+01, -5.2580e+01],\n        [-5.7991e+01, -5.2575e+01],\n        [-5.9390e+01, -5.2570e+01],\n        [-5.7008e+01, -5.2632e+01],\n        [-4.7918e+01, -7.0619e+01],\n        [-3.9816e+01, -4.7918e+01],\n        [-3.8725e+01, -3.9815e+01],\n        [-3.7140e+01, -3.8435e+01],\n        [-3.6464e+01, -3.6898e+01],\n        [-3.6408e+01, -3.5964e+01],\n        [-3.6531e+01, -3.5468e+01],\n        [-3.6508e+01, -3.5171e+01],\n        [-3.6641e+01, -3.4938e+01],\n        [-3.6341e+01, -3.4771e+01],\n        [-3.6156e+01, -3.4582e+01],\n        [-3.6288e+01, -3.4394e+01],\n        [-3.6159e+01, -3.4253e+01],\n        [-3.6221e+01, -3.4115e+01],\n        [-3.6258e+01, -3.4000e+01],\n        [-3.6155e+01, -3.3900e+01],\n        [-3.6188e+01, -3.3801e+01],\n        [-3.6192e+01, -3.3713e+01],\n        [-3.6198e+01, -3.3632e+01],\n        [-3.6178e+01, -3.3558e+01],\n        [-3.6228e+01, -3.3488e+01],\n        [-3.6245e+01, -3.3425e+01],\n        [-3.6296e+01, -3.3368e+01],\n        [-3.6213e+01, -3.3315e+01],\n        [-3.6142e+01, -3.3262e+01],\n        [-3.6211e+01, -3.3207e+01],\n        [-3.6110e+01, -3.3159e+01],\n        [-3.6128e+01, -3.3108e+01],\n        [-3.6285e+01, -3.3060e+01],\n        [-3.6263e+01, -3.3021e+01],\n        [-3.6308e+01, -3.2983e+01],\n        [-3.6192e+01, -3.2947e+01],\n        [-3.6155e+01, -3.2909e+01],\n        [-3.6180e+01, -3.2871e+01],\n        [-3.6200e+01, -3.2835e+01],\n        [-3.6148e+01, -3.2801e+01],\n        [-3.6176e+01, -3.2767e+01],\n        [-3.6142e+01, -3.2734e+01],\n        [-3.6169e+01, -3.2701e+01],\n        [-3.6158e+01, -3.2671e+01],\n        [-3.6154e+01, -3.2641e+01],\n        [-3.6132e+01, -3.2611e+01],\n        [-3.6131e+01, -3.2582e+01],\n        [-3.6277e+01, -3.2554e+01],\n        [-3.6219e+01, -3.2530e+01],\n        [-3.6087e+01, -3.2505e+01],\n        [-3.6099e+01, -3.2478e+01],\n        [-3.6109e+01, -3.2451e+01],\n        [-3.6191e+01, -3.2426e+01],\n        [-3.6090e+01, -3.2403e+01],\n        [-3.6109e+01, -3.2378e+01],\n        [-3.6047e+01, -3.2355e+01],\n        [-3.6083e+01, -3.2330e+01]], grad_fn=<SelectBackward>), tensor([-0.1331, -0.1331, -0.1331,  ..., -0.1331, -0.1331, -0.1331],\n       grad_fn=<ExpandBackward>), 0, 0)}))]\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nfrontend\nfrontend.stft\nfrontend.frontend\nfrontend.logmel\nnormalize\nencoder\nencoder.embed\nencoder.embed.conv\nencoder.embed.conv.0\nencoder.embed.conv.1\nencoder.embed.conv.2\nencoder.embed.conv.3\nencoder.embed.out\nencoder.embed.out.0\nencoder.embed.out.1\nencoder.embed.out.1.dropout\nencoder.encoders\nencoder.encoders.0\nencoder.encoders.0.self_attn\nencoder.encoders.0.self_attn.linear_q\nencoder.encoders.0.self_attn.linear_k\nencoder.encoders.0.self_attn.linear_v\nencoder.encoders.0.self_attn.linear_out\nencoder.encoders.0.self_attn.dropout\nencoder.encoders.0.feed_forward\nencoder.encoders.0.feed_forward.w_1\nencoder.encoders.0.feed_forward.w_2\nencoder.encoders.0.feed_forward.dropout\nencoder.encoders.0.feed_forward.activation\nencoder.encoders.0.norm1\nencoder.encoders.0.norm2\nencoder.encoders.0.dropout\nencoder.encoders.1\nencoder.encoders.1.self_attn\nencoder.encoders.1.self_attn.linear_q\nencoder.encoders.1.self_attn.linear_k\nencoder.encoders.1.self_attn.linear_v\nencoder.encoders.1.self_attn.linear_out\nencoder.encoders.1.self_attn.dropout\nencoder.encoders.1.feed_forward\nencoder.encoders.1.feed_forward.w_1\nencoder.encoders.1.feed_forward.w_2\nencoder.encoders.1.feed_forward.dropout\nencoder.encoders.1.norm1\nencoder.encoders.1.norm2\nencoder.encoders.1.dropout\nencoder.encoders.2\nencoder.encoders.2.self_attn\nencoder.encoders.2.self_attn.linear_q\nencoder.encoders.2.self_attn.linear_k\nencoder.encoders.2.self_attn.linear_v\nencoder.encoders.2.self_attn.linear_out\nencoder.encoders.2.self_attn.dropout\nencoder.encoders.2.feed_forward\nencoder.encoders.2.feed_forward.w_1\nencoder.encoders.2.feed_forward.w_2\nencoder.encoders.2.feed_forward.dropout\nencoder.encoders.2.norm1\nencoder.encoders.2.norm2\nencoder.encoders.2.dropout\nencoder.encoders.3\nencoder.encoders.3.self_attn\nencoder.encoders.3.self_attn.linear_q\nencoder.encoders.3.self_attn.linear_k\nencoder.encoders.3.self_attn.linear_v\nencoder.encoders.3.self_attn.linear_out\nencoder.encoders.3.self_attn.dropout\nencoder.encoders.3.feed_forward\nencoder.encoders.3.feed_forward.w_1\nencoder.encoders.3.feed_forward.w_2\nencoder.encoders.3.feed_forward.dropout\nencoder.encoders.3.norm1\nencoder.encoders.3.norm2\nencoder.encoders.3.dropout\nencoder.encoders.4\nencoder.encoders.4.self_attn\nencoder.encoders.4.self_attn.linear_q\nencoder.encoders.4.self_attn.linear_k\nencoder.encoders.4.self_attn.linear_v\nencoder.encoders.4.self_attn.linear_out\nencoder.encoders.4.self_attn.dropout\nencoder.encoders.4.feed_forward\nencoder.encoders.4.feed_forward.w_1\nencoder.encoders.4.feed_forward.w_2\nencoder.encoders.4.feed_forward.dropout\nencoder.encoders.4.norm1\nencoder.encoders.4.norm2\nencoder.encoders.4.dropout\nencoder.encoders.5\nencoder.encoders.5.self_attn\nencoder.encoders.5.self_attn.linear_q\nencoder.encoders.5.self_attn.linear_k\nencoder.encoders.5.self_attn.linear_v\nencoder.encoders.5.self_attn.linear_out\nencoder.encoders.5.self_attn.dropout\nencoder.encoders.5.feed_forward\nencoder.encoders.5.feed_forward.w_1\nencoder.encoders.5.feed_forward.w_2\nencoder.encoders.5.feed_forward.dropout\nencoder.encoders.5.norm1\nencoder.encoders.5.norm2\nencoder.encoders.5.dropout\nencoder.encoders.6\nencoder.encoders.6.self_attn\nencoder.encoders.6.self_attn.linear_q\nencoder.encoders.6.self_attn.linear_k\nencoder.encoders.6.self_attn.linear_v\nencoder.encoders.6.self_attn.linear_out\nencoder.encoders.6.self_attn.dropout\nencoder.encoders.6.feed_forward\nencoder.encoders.6.feed_forward.w_1\nencoder.encoders.6.feed_forward.w_2\nencoder.encoders.6.feed_forward.dropout\nencoder.encoders.6.norm1\nencoder.encoders.6.norm2\nencoder.encoders.6.dropout\nencoder.encoders.7\nencoder.encoders.7.self_attn\nencoder.encoders.7.self_attn.linear_q\nencoder.encoders.7.self_attn.linear_k\nencoder.encoders.7.self_attn.linear_v\nencoder.encoders.7.self_attn.linear_out\nencoder.encoders.7.self_attn.dropout\nencoder.encoders.7.feed_forward\nencoder.encoders.7.feed_forward.w_1\nencoder.encoders.7.feed_forward.w_2\nencoder.encoders.7.feed_forward.dropout\nencoder.encoders.7.norm1\nencoder.encoders.7.norm2\nencoder.encoders.7.dropout\nencoder.encoders.8\nencoder.encoders.8.self_attn\nencoder.encoders.8.self_attn.linear_q\nencoder.encoders.8.self_attn.linear_k\nencoder.encoders.8.self_attn.linear_v\nencoder.encoders.8.self_attn.linear_out\nencoder.encoders.8.self_attn.dropout\nencoder.encoders.8.feed_forward\nencoder.encoders.8.feed_forward.w_1\nencoder.encoders.8.feed_forward.w_2\nencoder.encoders.8.feed_forward.dropout\nencoder.encoders.8.norm1\nencoder.encoders.8.norm2\nencoder.encoders.8.dropout\nencoder.encoders.9\nencoder.encoders.9.self_attn\nencoder.encoders.9.self_attn.linear_q\nencoder.encoders.9.self_attn.linear_k\nencoder.encoders.9.self_attn.linear_v\nencoder.encoders.9.self_attn.linear_out\nencoder.encoders.9.self_attn.dropout\nencoder.encoders.9.feed_forward\nencoder.encoders.9.feed_forward.w_1\nencoder.encoders.9.feed_forward.w_2\nencoder.encoders.9.feed_forward.dropout\nencoder.encoders.9.norm1\nencoder.encoders.9.norm2\nencoder.encoders.9.dropout\nencoder.encoders.10\nencoder.encoders.10.self_attn\nencoder.encoders.10.self_attn.linear_q\nencoder.encoders.10.self_attn.linear_k\nencoder.encoders.10.self_attn.linear_v\nencoder.encoders.10.self_attn.linear_out\nencoder.encoders.10.self_attn.dropout\nencoder.encoders.10.feed_forward\nencoder.encoders.10.feed_forward.w_1\nencoder.encoders.10.feed_forward.w_2\nencoder.encoders.10.feed_forward.dropout\nencoder.encoders.10.norm1\nencoder.encoders.10.norm2\nencoder.encoders.10.dropout\nencoder.encoders.11\nencoder.encoders.11.self_attn\nencoder.encoders.11.self_attn.linear_q\nencoder.encoders.11.self_attn.linear_k\nencoder.encoders.11.self_attn.linear_v\nencoder.encoders.11.self_attn.linear_out\nencoder.encoders.11.self_attn.dropout\nencoder.encoders.11.feed_forward\nencoder.encoders.11.feed_forward.w_1\nencoder.encoders.11.feed_forward.w_2\nencoder.encoders.11.feed_forward.dropout\nencoder.encoders.11.norm1\nencoder.encoders.11.norm2\nencoder.encoders.11.dropout\nencoder.after_norm\ndecoder\ndecoder.embed\ndecoder.embed.0\ndecoder.embed.1\ndecoder.embed.1.dropout\ndecoder.after_norm\ndecoder.output_layer\ndecoder.decoders\ndecoder.decoders.0\ndecoder.decoders.0.self_attn\ndecoder.decoders.0.self_attn.linear_q\ndecoder.decoders.0.self_attn.linear_k\ndecoder.decoders.0.self_attn.linear_v\ndecoder.decoders.0.self_attn.linear_out\ndecoder.decoders.0.self_attn.dropout\ndecoder.decoders.0.src_attn\ndecoder.decoders.0.src_attn.linear_q\ndecoder.decoders.0.src_attn.linear_k\ndecoder.decoders.0.src_attn.linear_v\ndecoder.decoders.0.src_attn.linear_out\ndecoder.decoders.0.src_attn.dropout\ndecoder.decoders.0.feed_forward\ndecoder.decoders.0.feed_forward.w_1\ndecoder.decoders.0.feed_forward.w_2\ndecoder.decoders.0.feed_forward.dropout\ndecoder.decoders.0.norm1\ndecoder.decoders.0.norm2\ndecoder.decoders.0.norm3\ndecoder.decoders.0.dropout\ndecoder.decoders.1\ndecoder.decoders.1.self_attn\ndecoder.decoders.1.self_attn.linear_q\ndecoder.decoders.1.self_attn.linear_k\ndecoder.decoders.1.self_attn.linear_v\ndecoder.decoders.1.self_attn.linear_out\ndecoder.decoders.1.self_attn.dropout\ndecoder.decoders.1.src_attn\ndecoder.decoders.1.src_attn.linear_q\ndecoder.decoders.1.src_attn.linear_k\ndecoder.decoders.1.src_attn.linear_v\ndecoder.decoders.1.src_attn.linear_out\ndecoder.decoders.1.src_attn.dropout\ndecoder.decoders.1.feed_forward\ndecoder.decoders.1.feed_forward.w_1\ndecoder.decoders.1.feed_forward.w_2\ndecoder.decoders.1.feed_forward.dropout\ndecoder.decoders.1.norm1\ndecoder.decoders.1.norm2\ndecoder.decoders.1.norm3\ndecoder.decoders.1.dropout\ndecoder.decoders.2\ndecoder.decoders.2.self_attn\ndecoder.decoders.2.self_attn.linear_q\ndecoder.decoders.2.self_attn.linear_k\ndecoder.decoders.2.self_attn.linear_v\ndecoder.decoders.2.self_attn.linear_out\ndecoder.decoders.2.self_attn.dropout\ndecoder.decoders.2.src_attn\ndecoder.decoders.2.src_attn.linear_q\ndecoder.decoders.2.src_attn.linear_k\ndecoder.decoders.2.src_attn.linear_v\ndecoder.decoders.2.src_attn.linear_out\ndecoder.decoders.2.src_attn.dropout\ndecoder.decoders.2.feed_forward\ndecoder.decoders.2.feed_forward.w_1\ndecoder.decoders.2.feed_forward.w_2\ndecoder.decoders.2.feed_forward.dropout\ndecoder.decoders.2.norm1\ndecoder.decoders.2.norm2\ndecoder.decoders.2.norm3\ndecoder.decoders.2.dropout\ndecoder.decoders.3\ndecoder.decoders.3.self_attn\ndecoder.decoders.3.self_attn.linear_q\ndecoder.decoders.3.self_attn.linear_k\ndecoder.decoders.3.self_attn.linear_v\ndecoder.decoders.3.self_attn.linear_out\ndecoder.decoders.3.self_attn.dropout\ndecoder.decoders.3.src_attn\ndecoder.decoders.3.src_attn.linear_q\ndecoder.decoders.3.src_attn.linear_k\ndecoder.decoders.3.src_attn.linear_v\ndecoder.decoders.3.src_attn.linear_out\ndecoder.decoders.3.src_attn.dropout\ndecoder.decoders.3.feed_forward\ndecoder.decoders.3.feed_forward.w_1\ndecoder.decoders.3.feed_forward.w_2\ndecoder.decoders.3.feed_forward.dropout\ndecoder.decoders.3.norm1\ndecoder.decoders.3.norm2\ndecoder.decoders.3.norm3\ndecoder.decoders.3.dropout\ndecoder.decoders.4\ndecoder.decoders.4.self_attn\ndecoder.decoders.4.self_attn.linear_q\ndecoder.decoders.4.self_attn.linear_k\ndecoder.decoders.4.self_attn.linear_v\ndecoder.decoders.4.self_attn.linear_out\ndecoder.decoders.4.self_attn.dropout\ndecoder.decoders.4.src_attn\ndecoder.decoders.4.src_attn.linear_q\ndecoder.decoders.4.src_attn.linear_k\ndecoder.decoders.4.src_attn.linear_v\ndecoder.decoders.4.src_attn.linear_out\ndecoder.decoders.4.src_attn.dropout\ndecoder.decoders.4.feed_forward\ndecoder.decoders.4.feed_forward.w_1\ndecoder.decoders.4.feed_forward.w_2\ndecoder.decoders.4.feed_forward.dropout\ndecoder.decoders.4.norm1\ndecoder.decoders.4.norm2\ndecoder.decoders.4.norm3\ndecoder.decoders.4.dropout\ndecoder.decoders.5\ndecoder.decoders.5.self_attn\ndecoder.decoders.5.self_attn.linear_q\ndecoder.decoders.5.self_attn.linear_k\ndecoder.decoders.5.self_attn.linear_v\ndecoder.decoders.5.self_attn.linear_out\ndecoder.decoders.5.self_attn.dropout\ndecoder.decoders.5.src_attn\ndecoder.decoders.5.src_attn.linear_q\ndecoder.decoders.5.src_attn.linear_k\ndecoder.decoders.5.src_attn.linear_v\ndecoder.decoders.5.src_attn.linear_out\ndecoder.decoders.5.src_attn.dropout\ndecoder.decoders.5.feed_forward\ndecoder.decoders.5.feed_forward.w_1\ndecoder.decoders.5.feed_forward.w_2\ndecoder.decoders.5.feed_forward.dropout\ndecoder.decoders.5.norm1\ndecoder.decoders.5.norm2\ndecoder.decoders.5.norm3\ndecoder.decoders.5.dropout\nctc\nctc.ctc_lo\nctc.ctc_loss\ncriterion_att\ncriterion_att.criterion\n"
     ]
    }
   ],
   "source": [
    "# print(net.encoder)\n",
    "# print(\"#######################################################\")\n",
    "# print(net.decoder)\n",
    "for name, module in net.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 5000])\n"
     ]
    }
   ],
   "source": [
    "print(len(att_hook.output))"
   ]
  }
 ]
}