{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('speech': conda)",
   "metadata": {
    "interpreter": {
     "hash": "611231d50d89399c7812e642eac108257e44491cbc2ead4a7a526b1be52f90d6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import torch\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test wav for attention image extraction\n",
    "TEST_DATA_PATH = \"./data/dev_clean\"\n",
    "WAV_LIST_PATH = TEST_DATA_PATH + \"/wav.scp\"\n",
    "ANSWER_LIST_PATH = TEST_DATA_PATH + \"/text\"\n",
    "\n",
    "file_name_list = []\n",
    "speech_ans_list = []\n",
    "\n",
    "with open(WAV_LIST_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        num, name = line.split(' ')\n",
    "        file_name_list.append(name[:-1])\n",
    "\n",
    "with open(ANSWER_LIST_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        speech_ans_list.append(line[17:])\n",
    "\n",
    "# Prepare model\n",
    "d = ModelDownloader()\n",
    "\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack('Shinji Watanabe/librispeech_asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best'),\n",
    "    # Decoding parameters are not included in the model file\n",
    "    maxlenratio=0.0,\n",
    "    minlenratio=0.0,\n",
    "    beam_size=1,\n",
    "    ctc_weight=1.0,\n",
    "    lm_weight=0.0,\n",
    "    penalty=0.0,\n",
    "    nbest=1\n",
    ")\n",
    "# Add register hook for in encoder layers.\n",
    "net = speech2text.asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_num = 2 # selelct one of the wav in file_name_list\n",
    "speech, rate = soundfile.read(file_name_list[audio_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, ctc_out = speech2text(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctc_out)"
   ]
  }
 ]
}