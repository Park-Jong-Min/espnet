{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('espnet': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe19ea1dd1c022a555d1887e1747d5402a0438a9e4c1a077d5b483c4b395fede"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "from test_with_deleted_heads import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test wav for attention image extraction\n",
    "TEST_DATA_PATH = \"./data/dev_clean\"\n",
    "WAV_LIST_PATH = TEST_DATA_PATH + \"/wav.scp\"\n",
    "\n",
    "file_name_list = []\n",
    "audio_num = 1 # selelct one of the wav in file_name_list\n",
    "\n",
    "with open(WAV_LIST_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        num, name = line.split(' ')\n",
    "        file_name_list.append(name[:-1])\n",
    "\n",
    "speech, rate = soundfile.read(file_name_list[audio_num])\n",
    "\n",
    "# Prepare model\n",
    "d = ModelDownloader()\n",
    "\n",
    "ASR_MODEL_PATH = \"/home_data/jmpark/espnet/tools/anaconda/envs/espnet_1.7/lib/python3.8/site-packages/espnet_model_zoo/653d10049fdc264f694f57b49849343e/exp/asr_train_asr_transformer_e18_raw_bpe_sp/54epoch.pth\"\n",
    "LM_MODEL_PATH = \"/home_data/jmpark/espnet/tools/anaconda/envs/espnet_1.7.1/lib/python3.8/site-packages/espnet_model_zoo/653d10049fdc264f694f57b49849343e/exp/lm_train_lm_adam_bpe/17epoch.pth\"\n",
    "\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack('Shinji Watanabe/librispeech_asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best'),\n",
    "    # Decoding parameters are not included in the model file\n",
    "    maxlenratio=0.0,\n",
    "    minlenratio=0.0,\n",
    "    beam_size=1,\n",
    "    ctc_weight=0.4,\n",
    "    lm_weight=0.6,\n",
    "    penalty=0.0,\n",
    "    nbest=1\n",
    ")\n",
    "# Add register hook for in encoder layers.\n",
    "net = speech2text.asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_in = []\n",
    "attn_out = []\n",
    "\n",
    "def delete_head(self, input_tensor, output_tensor):\n",
    "    attn_in.append(input_tensor)\n",
    "    attn_out.append(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " for name, parameters in net.named_modules():\n",
    "        if 'encoder.encoders.0.self_attn' == name:\n",
    "            parameters.register_forward_hook(delete_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = speech2text(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 3.9737e+02, -3.6221e+00,  1.8986e+00,  ..., -2.3738e+00,\n           4.2530e-01,  5.1699e+00],\n         [ 4.0048e+02, -3.0599e+00,  4.4832e-01,  ..., -3.9692e+00,\n           1.3670e+00,  4.8992e+00],\n         [ 3.9536e+02, -3.0688e-01, -5.3080e-01,  ..., -3.9397e+00,\n           1.9183e+00,  3.0275e+00],\n         ...,\n         [ 4.1675e+02, -4.2605e+00,  2.4317e+00,  ..., -3.0579e+00,\n           2.2224e-01,  2.4086e+00],\n         [ 4.0817e+02, -5.0408e+00,  2.1389e+00,  ..., -2.9066e+00,\n           9.8136e-01,  3.2787e+00],\n         [ 4.1607e+02, -5.2573e+00,  1.3308e+00,  ..., -3.6109e+00,\n           8.6198e-01,  3.2930e+00]]])\ntorch.Size([1, 99, 512])\ntensor([[[[1.5484e-02, 2.7394e-02, 1.1775e-02,  ..., 1.5163e-02,\n           1.0450e-02, 1.6314e-02],\n          [9.5078e-03, 1.2301e-02, 6.5067e-03,  ..., 7.1893e-03,\n           5.2617e-03, 9.9207e-03],\n          [6.9793e-03, 9.2505e-03, 5.2825e-03,  ..., 4.1887e-03,\n           3.3733e-03, 5.6876e-03],\n          ...,\n          [1.3222e-02, 1.7597e-02, 1.1410e-02,  ..., 8.5301e-03,\n           6.2943e-03, 1.1353e-02],\n          [1.3649e-02, 2.1574e-02, 1.0666e-02,  ..., 1.1137e-02,\n           9.0814e-03, 1.1293e-02],\n          [1.6703e-02, 2.0434e-02, 1.2548e-02,  ..., 1.1479e-02,\n           7.0159e-03, 1.4227e-02]],\n\n         [[2.8958e-02, 2.8943e-02, 7.2252e-02,  ..., 2.4026e-02,\n           3.3329e-02, 2.1768e-02],\n          [4.0141e-02, 3.2531e-02, 8.9580e-02,  ..., 3.0907e-02,\n           4.5550e-02, 3.0296e-02],\n          [1.7686e-02, 2.1246e-02, 6.2707e-02,  ..., 1.4667e-02,\n           1.4896e-02, 1.5528e-02],\n          ...,\n          [2.7137e-02, 1.8638e-02, 9.0198e-02,  ..., 3.1766e-02,\n           5.0187e-02, 1.4905e-02],\n          [2.7277e-02, 1.4891e-02, 8.6424e-02,  ..., 3.6024e-02,\n           3.7512e-02, 1.8345e-02],\n          [2.7781e-02, 2.3577e-02, 5.5853e-02,  ..., 2.4613e-02,\n           2.9845e-02, 1.6204e-02]],\n\n         [[6.7164e-02, 1.0038e-03, 4.8753e-06,  ..., 7.1131e-02,\n           3.8106e-01, 9.2053e-04],\n          [9.9128e-01, 1.4905e-03, 1.9065e-05,  ..., 1.8682e-05,\n           2.4101e-05, 9.4967e-04],\n          [6.0514e-03, 9.9234e-01, 3.1095e-06,  ..., 4.2137e-06,\n           3.4758e-04, 2.5928e-04],\n          ...,\n          [7.9854e-05, 5.8639e-07, 5.6655e-09,  ..., 4.1625e-03,\n           5.7917e-02, 8.0370e-06],\n          [3.9071e-04, 4.5804e-07, 4.8068e-07,  ..., 4.3023e-01,\n           1.2121e-01, 2.0567e-04],\n          [1.4714e-04, 7.3506e-06, 1.6605e-09,  ..., 4.3353e-03,\n           9.5328e-01, 1.4702e-06]],\n\n         ...,\n\n         [[9.3944e-03, 7.2436e-03, 1.4419e-02,  ..., 2.6869e-03,\n           5.6404e-03, 1.6539e-03],\n          [6.2850e-03, 9.0105e-03, 1.0414e-02,  ..., 1.1187e-03,\n           2.3928e-03, 4.9333e-04],\n          [4.1683e-03, 1.3227e-02, 1.1788e-02,  ..., 1.2393e-03,\n           1.7994e-03, 1.4577e-03],\n          ...,\n          [1.4618e-02, 7.5460e-03, 8.9463e-03,  ..., 5.0664e-02,\n           1.4234e-01, 4.6179e-02],\n          [1.6773e-02, 6.3239e-03, 1.3054e-02,  ..., 5.2630e-02,\n           1.1669e-01, 4.6028e-02],\n          [9.8151e-03, 8.5117e-03, 1.0644e-02,  ..., 7.4390e-03,\n           2.1382e-02, 1.4366e-02]],\n\n         [[3.8683e-02, 8.1915e-02, 2.8751e-02,  ..., 1.1939e-02,\n           3.2658e-02, 2.2719e-02],\n          [2.5190e-02, 6.1742e-02, 2.0503e-02,  ..., 1.1009e-02,\n           2.6759e-02, 2.3852e-02],\n          [9.3360e-03, 4.1767e-02, 2.3298e-02,  ..., 5.6214e-03,\n           1.1576e-02, 1.4967e-02],\n          ...,\n          [3.7240e-02, 1.3184e-01, 5.0745e-02,  ..., 6.8676e-03,\n           1.9873e-02, 1.1511e-02],\n          [4.0983e-02, 1.1795e-01, 4.4156e-02,  ..., 7.0337e-03,\n           1.9025e-02, 1.2174e-02],\n          [4.6167e-02, 1.6630e-01, 7.5988e-02,  ..., 7.3185e-03,\n           1.9695e-02, 1.9657e-02]],\n\n         [[3.0159e-02, 5.5987e-02, 1.3584e-02,  ..., 3.1129e-02,\n           3.8211e-02, 2.6035e-02],\n          [3.2925e-02, 4.0823e-02, 1.8390e-02,  ..., 2.8847e-02,\n           2.8284e-02, 3.0600e-02],\n          [1.5769e-02, 1.9110e-02, 1.6007e-02,  ..., 1.0252e-02,\n           1.2691e-02, 1.4814e-02],\n          ...,\n          [4.8730e-02, 5.4768e-02, 1.0423e-02,  ..., 3.0083e-02,\n           5.9707e-02, 3.1525e-02],\n          [4.0182e-02, 6.6148e-02, 1.3146e-02,  ..., 3.0643e-02,\n           4.7882e-02, 2.9834e-02],\n          [5.1001e-02, 6.2620e-02, 1.8872e-02,  ..., 4.5622e-02,\n           5.2324e-02, 4.0864e-02]]]])\ntorch.Size([1, 8, 99, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_out[0][0])\n",
    "print(attn_out[0][0].shape)\n",
    "print(attn_out[0][1])\n",
    "print(attn_out[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True]]])\ntorch.Size([1, 1, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_in[0][0])\n",
    "print(attn_in[0][0].shape) # Query\n",
    "print(attn_in[0][1])\n",
    "print(attn_in[0][1].shape) # Key\n",
    "print(attn_in[0][2])\n",
    "print(attn_in[0][2].shape) # Value\n",
    "print(attn_in[0][3])\n",
    "print(attn_in[0][3].shape) # mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_heads = 8\n",
    "delete_head_idx = 0\n",
    "d_model = 512\n",
    "head_size = int(d_model/n_heads)\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if 'encoder.encoders.0.self_attn.linear_q.weight' == name:\n",
    "        param[:,delete_head_idx*head_size:(delete_head_idx+1)*head_size] = 0\n",
    "    elif 'encoder.encoders.0.self_attn.linear_q.bias' == name:\n",
    "        param[delete_head_idx*head_size:(delete_head_idx+1)*head_size] = 0\n",
    "    elif 'encoder.encoders.0.self_attn.linear_k.weight' == name:\n",
    "        param[:,delete_head_idx*head_size:(delete_head_idx+1)*head_size] = 0\n",
    "    elif 'encoder.encoders.0.self_attn.linear_k.bias' == name:\n",
    "        param[delete_head_idx*head_size:(delete_head_idx+1)*head_size] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.1580, -0.2107,  0.5066],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.3048,  0.5174, -0.0626],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.3999, -0.3829, -0.7384],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.3088, -0.2414, -0.4365],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.4422, -0.7058,  0.0361],\n        [ 0.0000,  0.0000,  0.0000,  ..., -0.2396, -0.2974,  0.4464]],\n       requires_grad=True)\nParameter containing:\ntensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5880e-01,\n         3.1541e-01, -5.8643e-02, -1.7953e-01, -2.1358e-01,  5.4950e-02,\n        -2.5978e-01,  2.3873e-01,  4.2573e-02, -4.1069e-01,  3.2592e-01,\n         5.7381e-02, -5.9726e-01,  1.5277e-02,  4.0875e-01, -2.8023e-01,\n         2.2883e-01,  4.3126e-01,  2.0255e-01, -9.6172e-01, -1.1348e-02,\n         1.5411e-01,  1.3980e-02,  5.3512e-01,  1.4117e-01,  4.7942e-01,\n        -5.6316e-02,  5.5141e-02, -2.6102e-01,  8.5780e-02, -1.6999e-01,\n         9.9414e-02, -1.3441e-01, -5.1107e-01, -8.8951e-03, -9.2741e-02,\n        -2.2358e-01, -3.5434e-01, -9.2187e-02,  9.5891e-01,  6.3335e-01,\n        -4.4678e-01, -2.5636e-01, -1.9608e-02,  1.3273e-01,  1.3970e-01,\n        -4.2304e-01,  9.8399e-02,  1.1203e-01, -1.1073e-01,  1.9103e-01,\n        -1.7012e-01, -5.4162e-02,  1.5921e-01, -9.0037e-02,  1.9668e-01,\n         6.6653e-01,  1.8961e-01, -4.5791e-02,  1.6120e-01,  2.5339e-01,\n         3.4919e-01, -1.5708e-02, -3.0771e-01, -3.4883e-02, -9.7553e-01,\n        -2.6954e-01,  2.2379e-01, -4.6100e-01,  7.5018e-01, -1.2042e+00,\n         2.2224e-01,  2.9831e-01, -7.9447e-01,  1.1274e-01, -1.3830e-01,\n        -1.0097e+00, -7.6413e-01, -2.1565e+00,  1.5817e+00, -2.0121e-01,\n         2.4567e-01, -1.1901e+00,  7.3535e-01, -5.0787e-01, -7.8030e-01,\n         1.5626e-01, -4.5118e-01, -5.3529e-01,  8.8096e-03, -2.4329e-01,\n         7.7713e-01,  6.3736e-01, -4.5822e-01, -1.7742e+00,  1.4990e+00,\n         2.6566e-02,  2.2757e+00, -5.2175e-01, -8.7219e-01,  5.7541e-01,\n        -1.2183e+00,  1.2772e+00,  7.1304e-01, -1.6422e+00, -2.8357e-02,\n        -4.3123e-01,  6.3390e-01,  8.7681e-02, -7.3701e-01,  1.5201e-01,\n         8.9077e-01, -9.6198e-02, -4.1445e-01,  1.1249e+00, -3.3236e-01,\n         8.2243e-01,  2.5911e-01, -5.5654e-01,  8.8738e-01, -8.7588e-01,\n         2.9525e-01,  1.8317e-01,  7.1478e-02,  5.4775e-01,  1.2172e+00,\n         8.7117e-01, -2.1311e-01, -3.8831e-03, -9.1120e-01, -5.2352e-03,\n        -5.2695e-01,  1.3492e-01, -1.0120e-01, -7.3971e-02,  7.6745e-01,\n         1.2687e-01,  3.8254e-01,  2.4215e-01,  3.6903e-01, -2.5929e-01,\n        -1.0900e+00, -2.4849e-02, -5.0516e-01, -9.0166e-02,  9.0067e-02,\n        -1.4705e-01, -1.6096e-01, -4.2041e-01, -4.9588e-03, -3.4968e-01,\n         1.1786e-02, -7.2603e-02,  1.3767e-01,  1.9038e-01, -2.6056e-01,\n         2.0952e-01,  1.2390e-01, -1.0955e+00,  3.4164e-01,  8.4998e-01,\n        -2.6249e-01, -7.6838e-01, -7.2351e-01, -4.5766e-01,  1.0261e+00,\n        -4.1545e-02,  1.1294e+00,  4.3567e-02,  1.0018e+00, -1.0948e-02,\n        -9.7324e-02, -6.3935e-02, -4.3273e-01, -2.5163e-01,  4.2429e-01,\n         2.9834e-01,  3.3228e-02,  2.3896e-01, -8.8599e-02,  1.0536e+00,\n        -7.0948e-02, -2.6572e-01,  6.3702e-01,  2.8257e-02, -3.0857e-02,\n        -8.2835e-02,  5.5090e-02,  2.0519e-03, -3.9213e-01,  1.0090e-01,\n         3.6078e-01, -8.8557e-01, -4.4204e-01,  3.0271e-01,  1.7094e-01,\n         5.1612e-01,  3.7366e-01,  1.8793e-01,  6.9611e-01, -2.5256e-01,\n        -5.7164e-01,  2.0491e-01,  1.8655e-01,  2.0488e-01, -5.0211e-03,\n         4.2633e-01, -2.4803e-01,  2.3406e-01,  1.1608e-01,  1.3579e-01,\n        -1.0091e-01, -6.0303e-01, -2.3374e-01,  1.9912e-01,  2.6545e-01,\n        -4.9151e-01,  9.8236e-01,  2.8650e-01,  3.0519e-01,  8.3273e-02,\n         2.0545e-02, -3.9320e-01,  9.1415e-01,  2.3714e-01,  5.7063e-01,\n        -5.6000e-03,  1.6532e-01,  4.7258e-01,  4.8048e-03,  1.3442e+00,\n        -2.3480e-01, -1.1591e-01, -9.4014e-02,  8.9360e-02, -3.5796e-01,\n         9.3671e-01,  3.0661e-01,  1.6603e-01, -4.0648e-01, -3.5329e-01,\n        -2.6067e-01, -3.5212e-01, -8.5834e-01, -2.4682e-01,  3.7979e-01,\n        -5.4041e-01,  2.8086e-01, -1.2716e-01, -8.9164e-02,  1.2360e-01,\n         2.2015e-01,  3.5391e-01,  2.5349e-01, -3.7092e-01, -4.9063e-01,\n         1.4206e-01, -6.5483e-01, -7.2084e-02, -2.8812e-01, -2.3391e-01,\n         1.5999e+00,  1.5669e-01,  1.1940e-01,  1.6102e-01, -9.6625e-01,\n         6.8996e-01,  1.1861e-01, -9.0737e-01,  8.1171e-03, -4.1686e-01,\n        -7.1580e-02,  9.6939e-02, -6.4970e-01,  5.6086e-01,  1.4532e-02,\n         4.9837e-02,  2.7248e-01, -3.7209e-01, -4.6060e-01, -1.7123e-01,\n        -5.7169e-02,  1.0948e-02,  3.9258e-01,  9.2123e-02, -1.2270e-01,\n         1.5229e-01, -2.2973e-01,  2.4170e-01, -1.4340e-01, -2.1725e-01,\n        -3.1222e-01,  4.5030e-01, -5.8779e-01, -4.1261e-01,  4.1751e-01,\n        -6.7521e-02, -4.5073e-01, -1.8634e-01, -6.4431e-02, -4.0850e-01,\n         2.8747e-01,  1.0656e-01, -1.0456e+00, -4.7434e-01,  2.7050e-01,\n         1.2177e-01, -2.4561e-01, -8.4961e-01,  4.3595e-01,  1.3396e-01,\n        -8.0294e-01, -1.2935e-01,  6.1442e-01, -4.4085e-02, -3.7554e-01,\n         2.5725e-01, -5.2987e-01,  1.2422e-01,  9.7710e-02, -6.2099e-01,\n         7.1998e-02,  1.6248e-01, -1.7535e-01, -2.1970e-01,  8.3619e-03,\n         5.6155e-01, -8.6782e-02,  5.9810e-02,  3.8681e-01,  8.0106e-02,\n        -2.3315e-01, -7.6677e-02, -7.0399e-02,  5.9144e-02, -2.6753e-01,\n        -1.8051e-01,  1.3552e-01, -4.4865e-01, -1.3675e-02,  7.3106e-03,\n         1.4792e-01, -8.3377e-02, -9.5131e-01,  1.2649e-01,  8.6484e-02,\n        -9.8283e-02,  3.3626e-01, -1.5787e-01,  2.2954e-02, -1.1583e-01,\n         2.9246e-01,  7.1135e-01,  3.5477e-03, -1.5001e-01,  8.6288e-02,\n        -8.2633e-02,  3.4337e-01,  3.6284e-01, -3.7853e-01,  1.4230e-01,\n        -1.8471e-02,  4.3975e-02,  1.6120e-01, -1.0045e-01, -2.4090e-01,\n        -6.2042e-02,  8.3717e-01, -3.9849e-01, -8.3820e-01,  3.4679e-01,\n        -3.7361e-01,  4.1901e-01,  1.7304e-01, -1.4536e-01, -3.3053e-02,\n        -2.7301e-01,  1.1932e-01,  1.0058e-01,  3.7117e-02,  3.7911e-01,\n        -2.3643e-01, -6.2117e-03, -2.8194e-02, -2.7899e-02, -1.4573e-01,\n        -1.0852e-03, -7.5313e-02,  1.0363e-02, -4.0410e-02, -2.6033e-02,\n         3.3615e-02,  2.7436e-02, -1.6352e-01,  6.8108e-03,  1.6096e-01,\n        -1.3826e-01,  1.4973e-01,  1.1253e-01, -4.2433e-02, -5.1125e-02,\n         7.8811e-01,  6.5159e-02, -1.8553e-01, -1.1559e-02,  1.2885e+00,\n        -1.4475e-01, -7.7651e-01, -3.8306e-01, -1.6073e-01,  2.3464e-02,\n         4.3586e-01,  2.2888e-01,  3.6145e-02,  3.1818e-01,  2.0932e-02,\n         1.3316e-01, -4.8080e-02, -2.0449e-01, -5.3956e-04,  3.5572e-02,\n        -7.3298e-03,  8.8054e-03,  1.5810e-01, -9.7546e-01, -2.9225e-01,\n         3.8864e-01, -8.0446e-01, -8.1619e-01,  8.0469e-01,  1.3910e-01,\n        -9.5175e-02,  8.1681e-02,  3.5964e-01,  1.0417e-01,  3.3288e-01,\n         2.6526e-01,  6.3734e-02,  2.1194e-01,  2.9427e-02, -1.7439e+00,\n         5.8670e-02, -5.1774e-01,  1.7782e+00,  4.6235e-02, -1.4827e-01,\n         4.0285e-02,  4.1610e-01], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if 'encoder.encoders.0.self_attn.linear_q.weight' == name:\n",
    "        print(param.view(n_batch, -1, n_heads, head_size))\n",
    "    elif 'encoder.encoders.0.self_attn.linear_q.bias' == name:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import torch\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "https://zenodo.org/record/4030677/files/asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best.zip?download=1: 100%|██████████| 970M/970M [04:52<00:00, 3.48MB/s]\n"
     ]
    }
   ],
   "source": [
    "d = ModelDownloader(\"/home_data/jmpark/.cache/espnet\")\n",
    "\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack('Shinji Watanabe/librispeech_asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best'),\n",
    "    # Decoding parameters are not included in the model file\n",
    "    maxlenratio=0.0,\n",
    "    minlenratio=0.0,\n",
    "    beam_size=1,\n",
    "    ctc_weight=0.4,\n",
    "    lm_weight=0.6,\n",
    "    penalty=0.0,\n",
    "    nbest=1\n",
    ")"
   ]
  }
 ]
}