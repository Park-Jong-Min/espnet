{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('espnet': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fe19ea1dd1c022a555d1887e1747d5402a0438a9e4c1a077d5b483c4b395fede"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
    "from test_with_deleted_heads import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set test wav for attention image extraction\n",
    "TEST_DATA_PATH = \"./data/dev_clean\"\n",
    "WAV_LIST_PATH = TEST_DATA_PATH + \"/wav.scp\"\n",
    "\n",
    "file_name_list = []\n",
    "audio_num = 1 # selelct one of the wav in file_name_list\n",
    "\n",
    "with open(WAV_LIST_PATH, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        num, name = line.split(' ')\n",
    "        file_name_list.append(name[:-1])\n",
    "\n",
    "speech, rate = soundfile.read(file_name_list[audio_num])\n",
    "\n",
    "# Prepare model\n",
    "d = ModelDownloader()\n",
    "\n",
    "ASR_MODEL_PATH = \"/home_data/jmpark/espnet/tools/anaconda/envs/espnet_1.7/lib/python3.8/site-packages/espnet_model_zoo/653d10049fdc264f694f57b49849343e/exp/asr_train_asr_transformer_e18_raw_bpe_sp/54epoch.pth\"\n",
    "LM_MODEL_PATH = \"/home_data/jmpark/espnet/tools/anaconda/envs/espnet_1.7.1/lib/python3.8/site-packages/espnet_model_zoo/653d10049fdc264f694f57b49849343e/exp/lm_train_lm_adam_bpe/17epoch.pth\"\n",
    "\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack('Shinji Watanabe/librispeech_asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best'),\n",
    "    # Decoding parameters are not included in the model file\n",
    "    maxlenratio=0.0,\n",
    "    minlenratio=0.0,\n",
    "    beam_size=1,\n",
    "    ctc_weight=0.4,\n",
    "    lm_weight=0.6,\n",
    "    penalty=0.0,\n",
    "    nbest=1\n",
    ")\n",
    "# Add register hook for in encoder layers.\n",
    "net = speech2text.asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_in = []\n",
    "attn_out = []\n",
    "\n",
    "def delete_head(self, input_tensor, output_tensor):\n",
    "    attn_in.append(input_tensor)\n",
    "    attn_out.append(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " for name, parameters in net.named_modules():\n",
    "        if 'encoder.encoders.0.self_attn' == name:\n",
    "            parameters.register_forward_hook(delete_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = speech2text(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 3.9737e+02, -3.6221e+00,  1.8986e+00,  ..., -2.3738e+00,\n           4.2530e-01,  5.1699e+00],\n         [ 4.0048e+02, -3.0599e+00,  4.4832e-01,  ..., -3.9692e+00,\n           1.3670e+00,  4.8992e+00],\n         [ 3.9536e+02, -3.0688e-01, -5.3080e-01,  ..., -3.9397e+00,\n           1.9183e+00,  3.0275e+00],\n         ...,\n         [ 4.1675e+02, -4.2605e+00,  2.4317e+00,  ..., -3.0579e+00,\n           2.2224e-01,  2.4086e+00],\n         [ 4.0817e+02, -5.0408e+00,  2.1389e+00,  ..., -2.9066e+00,\n           9.8136e-01,  3.2787e+00],\n         [ 4.1607e+02, -5.2573e+00,  1.3308e+00,  ..., -3.6109e+00,\n           8.6198e-01,  3.2930e+00]]])\ntorch.Size([1, 99, 512])\ntensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[6.7164e-02, 1.0038e-03, 4.8753e-06,  ..., 7.1131e-02,\n           3.8106e-01, 9.2053e-04],\n          [9.9128e-01, 1.4905e-03, 1.9065e-05,  ..., 1.8682e-05,\n           2.4101e-05, 9.4967e-04],\n          [6.0514e-03, 9.9234e-01, 3.1095e-06,  ..., 4.2137e-06,\n           3.4758e-04, 2.5928e-04],\n          ...,\n          [7.9854e-05, 5.8639e-07, 5.6655e-09,  ..., 4.1625e-03,\n           5.7917e-02, 8.0370e-06],\n          [3.9071e-04, 4.5804e-07, 4.8068e-07,  ..., 4.3023e-01,\n           1.2121e-01, 2.0567e-04],\n          [1.4714e-04, 7.3506e-06, 1.6605e-09,  ..., 4.3353e-03,\n           9.5328e-01, 1.4702e-06]],\n\n         ...,\n\n         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]],\n\n         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          ...,\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00],\n          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n           0.0000e+00, 0.0000e+00]]]])\ntorch.Size([1, 8, 99, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_out[0][0])\n",
    "print(attn_out[0][0].shape)\n",
    "print(attn_out[0][1])\n",
    "print(attn_out[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[-0.2267,  0.0653, -0.0380,  ...,  0.0141, -0.0138,  0.0086],\n         [-0.1821,  0.0681, -0.0252,  ..., -0.0771,  0.0249, -0.0277],\n         [-0.1252,  0.0625, -0.0123,  ..., -0.0064,  0.0329, -0.0025],\n         ...,\n         [-0.2995,  0.0555, -0.0312,  ..., -0.0071, -0.0071, -0.0167],\n         [-0.2829,  0.0499, -0.0166,  ..., -0.0018, -0.0358, -0.0071],\n         [-0.2371,  0.0528, -0.0296,  ..., -0.0003,  0.0147,  0.0129]]])\ntorch.Size([1, 99, 512])\ntensor([[[True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True,\n          True, True, True, True, True, True, True, True, True, True, True]]])\ntorch.Size([1, 1, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_in[0][0])\n",
    "print(attn_in[0][0].shape) # Query\n",
    "print(attn_in[0][1])\n",
    "print(attn_in[0][1].shape) # Key\n",
    "print(attn_in[0][2])\n",
    "print(attn_in[0][2].shape) # Value\n",
    "print(attn_in[0][3])\n",
    "print(attn_in[0][3].shape) # mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 99, 512])\ntorch.Size([1, 8, 99, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_out[0][0].shape)\n",
    "print(attn_out[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 99, 512])\ntorch.Size([1, 99, 512])\ntorch.Size([1, 99, 512])\ntorch.Size([1, 1, 99])\n"
     ]
    }
   ],
   "source": [
    "print(attn_in[0][0].shape)\n",
    "print(attn_in[0][1].shape)\n",
    "print(attn_in[0][2].shape)\n",
    "print(attn_in[0][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attn = MultiHeadedAttention(8, 512, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}